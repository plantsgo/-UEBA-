{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "import math\n",
    "import gc\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint,ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(path+\"train_data.csv\",encoding=\"gbk\")\n",
    "test=pd.read_csv(path+\"A_test_data.csv\",encoding=\"gbk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(data):\n",
    "    data[\"time\"]=pd.to_datetime(data[\"time\"])\n",
    "    data[\"hour\"]=data[\"time\"].dt.hour*60+data[\"time\"].dt.minute\n",
    "    \n",
    "    for num in [\"hour\"]:\n",
    "        st = preprocessing.StandardScaler()\n",
    "        data[num]=st.fit_transform(data[[num]].values)\n",
    "    \n",
    "    for fe in ['account', 'IP', 'url','switchIP']:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        data[fe]=le.fit_transform(data[fe])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.concat([train,test]).reset_index(drop=True)\n",
    "data=create_features(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=data[~data.ret.isna()].reset_index(drop=True)\n",
    "test_data=data[data.ret.isna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_features=['account', 'IP', 'url', 'switchIP']\n",
    "num_features=[\"hour\"]\n",
    "\n",
    "train_x = {}\n",
    "test_x={}\n",
    "for col in cate_features:\n",
    "    train_x[col] = train_data[col].values.astype('float64')\n",
    "    test_x[col] = test_data[col].values.astype('float64')\n",
    "    \n",
    "for col in num_features:\n",
    "    train_x[col] = train_data[col].values.astype('float64')\n",
    "    test_x[col] = test_data[col].values.astype('float64')\n",
    "    \n",
    "train_y=train_data[\"ret\"].astype(\"float64\").values.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e2b455641b86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mskf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfolds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0mte_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[0mtest_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[0mtest_pred_cv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    cat_input=[]\n",
    "    cat_emb=[]\n",
    "    for cat in cate_features:\n",
    "        cat_inp = Input(shape=(1,),name=cat)\n",
    "        cat_input.append(cat_inp)\n",
    "        embed = Embedding(data[cat].max()+1, 200, input_length=1, trainable=True)(cat_inp)\n",
    "        cat_emb.append(Flatten()(embed))\n",
    "    \n",
    "    num_input=[]\n",
    "    for num in num_features:\n",
    "        num_inp = Input(shape=(1,),name=num)\n",
    "        num_input.append(num_inp)\n",
    "    \n",
    "    \n",
    "    x=concatenate(cat_emb+num_input, axis=1)\n",
    "    fc1 = Dense(1024, activation='relu')(x)\n",
    "    fc2 = Dense(512, activation='relu')(fc1)\n",
    "    fc2 = Dense(256, activation='relu')(fc2)\n",
    "    output = Dense(1, activation=\"relu\")(fc2)\n",
    "    model = Model(inputs=cat_input+num_input, outputs=output)\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mse\"])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "folds = 5\n",
    "seed = 2018\n",
    "skf = KFold(n_splits=folds,shuffle=True, random_state=seed)\n",
    "\n",
    "te_pred=np.zeros((train_data.shape[0],1))\n",
    "test_pred=np.zeros((test_data.shape[0],1))\n",
    "test_pred_cv=np.zeros((5,test_data.shape[0],1))\n",
    "cnt=0\n",
    "score=0\n",
    "score_cv_list=[]\n",
    "for ii,(idx_train, idx_val) in enumerate(skf.split(train_data)):\n",
    "    X_train_tr={}\n",
    "    X_train_te={}\n",
    "    for col in cate_features+num_features:\n",
    "        X_train_tr[col]=train_x[col][idx_train]\n",
    "        X_train_te[col]=train_x[col][idx_val]\n",
    "    \n",
    "    \n",
    "    y_tr=train_y[idx_train]\n",
    "    y_te=train_y[idx_val]\n",
    "\n",
    "    model = get_model()\n",
    "    early_stop = EarlyStopping(patience=2)\n",
    "    check_point = ModelCheckpoint(path+'best_model.hdf5', monitor=\"val_loss\", mode=\"min\", save_best_only=True, verbose=1)\n",
    "    plateau = ReduceLROnPlateau(\n",
    "        monitor='val_loss', factor=0.75, patience=5, verbose=0,\n",
    "        mode='min')\n",
    "    \n",
    "    history = model.fit(X_train_tr, y_tr, batch_size=64, epochs=100, verbose=1, validation_data=(X_train_te,y_te),\n",
    "                        callbacks=[check_point,plateau])\n",
    "\n",
    "    model.load_weights(path+'best_model.hdf5')\n",
    "    \n",
    "    preds_te = model.predict(X_train_te,batch_size=1024)\n",
    "    score_cv = (1/(1+np.sin(np.arctan(mean_squared_error(y_te, preds_te)**0.5))))\n",
    "    score_cv_list.append(score_cv)\n",
    "    print(score_cv_list)\n",
    "    te_pred[idx_val] = preds_te\n",
    "    preds = model.predict(test_x,batch_size=1024)\n",
    "    test_pred_cv[ii, :] = preds\n",
    "    #break\n",
    "\n",
    "test_pred[:]=test_pred_cv.mean(axis=0)\n",
    "\n",
    "score=(1/(1+np.sin(np.arctan(mean_squared_error(train_y, te_pred)**0.5))))\n",
    "score=str(score)[:7]\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub=test[[\"id\"]].copy()\n",
    "sub[\"ret\"]=test_pred\n",
    "sub.to_csv(path+\"sub_nn_%s.csv\"%m,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
